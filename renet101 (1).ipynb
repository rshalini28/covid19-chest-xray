{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport datetime\nimport glob as glob\nimport numpy as np\nimport cv2\n\nimport keras\nimport tensorflow as tf\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D,Dropout\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.optimizers import SGD\nfrom tensorflow.keras.models import load_model\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing import image\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(img):\n    width, height = img.shape[0], img.shape[1]\n    img = image.array_to_img(img, scale=False)\n\n    # Crop 48x48px\n    desired_width, desired_height = 224, 224\n\n    if width < desired_width:\n        desired_width = width\n    start_x = np.maximum(0, int((width-desired_width)/2))\n\n    img = img.crop((start_x, np.maximum(0, height-desired_height), start_x+desired_width, height))\n    img = img.resize((224, 224))\n\n    img = image.img_to_array(img)\n    return img / 255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(train_dir, validate_dir):\n    img_width, img_height = 224,224\n    batch_size =16\n    # data pre-processing for training\n    train_datagen =  ImageDataGenerator(\n        rescale=1./255,\n        rotation_range = 10,\n        zoom_range = [1.00, 1.00],\n        horizontal_flip = True,\n        fill_mode = 'nearest')\n    \n\n    # data pre-processing for validation\n    validate_datagen =  ImageDataGenerator(rescale=1./255)\n\n    # generate and store training data\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size = (img_width, img_height),\n        batch_size = batch_size)\n\n    # generate and store validation data\n    validate_generator = validate_datagen.flow_from_directory(\n        validate_dir,\n        target_size = (img_width, img_height),\n        batch_size = batch_size)\n    \n    return train_generator, validate_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"../input/chest-xray-pneumonia/chest_xray/train\"\nvalidation_dir = \"../input/chest-xray-pneumonia/chest_xray/val\"\ntest_dir = \"../input/chest-xray-pneumonia/chest_xray/test\"\n# train_generator, validate_generator = preprocess_data(train_dir, validate_dir)# Prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(rotation_range=40,\n                                   rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   validation_split=0.1)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    target_size=(224,224),\n                                                    batch_size=16,\n                                                    class_mode='categorical')\n\nvalidation_generator = train_datagen.flow_from_directory(validation_dir,\n                                                    target_size=(224,224),\n                                                    batch_size=16,\n                                                    class_mode='categorical'\n                                                        )\n\ntest_generator = test_datagen.flow_from_directory(test_dir,\n                                                  target_size=(224,224),\n                                                  batch_size=16,\n                                                  class_mode='categorical'\n                                                 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(rotation_range=40,\n                                   rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   validation_split=0.1)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    target_size=(224,224),\n                                                    batch_size=16,\n                                                    class_mode='categorical')\n\nvalidation_generator = train_datagen.flow_from_directory(validation_dir,\n                                                    target_size=(224,224),\n                                                    batch_size=16,\n                                                    class_mode='categorical'\n                                                        )\n\ntest_generator = test_datagen.flow_from_directory(test_dir,\n                                                  target_size=(224,224),\n                                                  batch_size=16,\n                                                  class_mode='categorical'\n                                                 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras.applications.resnet import ResNet101\nfrom tensorflow.python.keras import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load pre trained Xception model\nbase_model=tf.keras.applications.resnet.ResNet101(include_top=False, weights='imagenet')\nfor layer in base_model.layers:\n    layer.trainable = False\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n #and a logistic layer -- let's say we have 2 classes\npredictions = Dense(2, activation='softmax')(x)\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n\n# add a global spatial average pooling layer\n#x = base_model.output\n# let's add a fully-connected layer\n#x = Dense(1024, activation='relu')(x)\n #and a logistic layer -- let's say we have 200 classes\n#predictions = Dense(2, activation='softmax')(x)\n# this is the model we will train\n#model = Model(inputs=base_model.input, outputs=predictions)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning = 0.0001\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer=Adam(lr=learning, beta_1=0.85, beta_2=0.999, amsgrad=False), loss='categorical_crossentropy',metrics=['accuracy'])\n#Summary of Xception Model\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nmodel.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nNUM_EPOCHS = 30\nbatch_size=8\nhistory = model.fit_generator(\n    train_generator,\n        epochs = NUM_EPOCHS,\n        validation_data=validation_generator,\n    callbacks=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model):\n    \n    predict_datagen =  ImageDataGenerator(rescale=1./255)\n    test_dir = \"../input/chest-xray-pneumonia/chest_xray/test\"\n    \n    # generate and store validation data\n    predict_generator = predict_datagen.flow_from_directory(\n        test_dir,\n        class_mode=None,\n        target_size = (224, 224),\n        shuffle=False)\n\n    pred = model.predict_generator(predict_generator)\n    predicted_class_indices=np.argmax(pred,axis=1)\n    \n    return predicted_class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npredicted_class_indices = test(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_datagen =  ImageDataGenerator(rescale=1./255,\n                                     preprocessing_function=preprocess)\ntest_dir = \"../input/chest-xray-pneumonia/chest_xray/test\"\n\n# generate and store validation data\npredict_generator = predict_datagen.flow_from_directory(\n    test_dir,\n    class_mode=None,\n    target_size = (224, 224),\n    shuffle=False)\n\npred = model.predict_generator(predict_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nN = NUM_EPOCHS\nplt.style.use(\"seaborn-white\")\nplt.figure()\nplt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"test_loss\")\nplt.title(\"Training Loss on Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")\n\nplt.style.use(\"seaborn-white\")\nplt.figure()\nplt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"test_acc\")\nplt.title(\"Training Accuracy on Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n\nLABELS = [\"covid-19\",\"normal\"]\n\ndef show_confusion_matrix(validations, predictions):\n    matrix = confusion_matrix(validations, predictions)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(matrix,\n                cmap=\"coolwarm\",\n                linecolor='white',\n                linewidths=1,\n                xticklabels=LABELS,\n                yticklabels=LABELS,\n                annot=True,\n                fmt=\"d\")\n    plt.title(\"Confusion Matrix\")\n    plt.ylabel(\"True Label\")\n    plt.xlabel(\"Predicted Label\")\n    plt.show()\n\nfilenames = validation_generator.filenames\nnb_samples = len(filenames)\n\nY_pred = model.predict_generator(validation_generator,(nb_samples//batch_size))\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nshow_confusion_matrix(validation_generator.classes, y_pred)\n\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\n\ntarget_names = [\"covid-19\",\"normal\"]\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n\n\n\n# Plot linewidth.\nlw = 2\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(2):\n    fpr[i], tpr[i], _ = roc_curve(validation_generator.classes, y_pred)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure()\nlw = 2\nplt.plot(fpr[0], tpr[0], color='darkorange',\n       lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([-0.01, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nplt.savefig('foo.png')\nplt.savefig('foo.pdf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\nfilenames=predict_generator.filenames\nresults=pd.DataFrame({\"ID\":filenames,\n                      \"Label\":predictions})\nresults","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}